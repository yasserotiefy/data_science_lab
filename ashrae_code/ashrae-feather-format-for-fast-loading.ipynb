{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ASHRAE - Great Energy Predictor III\n","\n","\n","SUMMARY: `test.csv` is big data and takes time to load. I will convert competition data to feather format for fast `pandas.DataFrame` loading!"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import random\n","import gc\n","\n","import tqdm\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# Copy from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n","# Modified to support timestamp type\n","# Modified to add option to use float16 or not. feather format does not support float16.\n","from pandas.api.types import is_datetime64_any_dtype as is_datetime\n","\n","def reduce_mem_usage(df, use_float16=False):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.        \n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","    \n","    for col in df.columns:\n","        if is_datetime(df[col]):\n","            # skip datetime type\n","            continue\n","        col_type = df[col].dtype\n","        \n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            df[col] = df[col].astype('category')\n","\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","    \n","    return df\n","\n","\n","def import_data(file):\n","    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n","    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n","    df = reduce_mem_usage(df)\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 29 s, sys: 4.85 s, total: 33.9 s\n","Wall time: 33.9 s\n"]}],"source":["%%time\n","\n","# Read data...\n","root = '../ashrae_data'\n","\n","train_df = pd.read_csv(os.path.join(root, 'train.csv'))\n","weather_train_df = pd.read_csv(os.path.join(root, 'weather_train.csv'))\n","test_df = pd.read_csv(os.path.join(root, 'test.csv'))\n","weather_test_df = pd.read_csv(os.path.join(root, 'weather_test.csv'))\n","building_meta_df = pd.read_csv(os.path.join(root, 'building_metadata.csv'))\n","sample_submission = pd.read_csv(os.path.join(root, 'sample_submission.csv'))"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n","test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n","weather_train_df['timestamp'] = pd.to_datetime(weather_train_df['timestamp'])\n","weather_test_df['timestamp'] = pd.to_datetime(weather_test_df['timestamp'])"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["# # categorize primary_use column to reduce memory on merge...\n","\n","# primary_use_dict = {key: value for value, key in enumerate(primary_use_list)} \n","# print('primary_use_dict: ', primary_use_dict)\n","# building_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)\n","\n","# gc.collect()"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory usage of dataframe is 616.95 MB\n","Memory usage after optimization is: 289.19 MB\n","Decreased by 53.1%\n","Memory usage of dataframe is 1272.51 MB\n","Memory usage after optimization is: 596.49 MB\n","Decreased by 53.1%\n","Memory usage of dataframe is 0.07 MB\n","Memory usage after optimization is: 0.02 MB\n","Decreased by 65.4%\n","Memory usage of dataframe is 9.60 MB\n","Memory usage after optimization is: 4.93 MB\n","Decreased by 48.6%\n","Memory usage of dataframe is 19.04 MB\n","Memory usage after optimization is: 9.78 MB\n","Decreased by 48.6%\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site_id</th>\n","      <th>timestamp</th>\n","      <th>air_temperature</th>\n","      <th>cloud_coverage</th>\n","      <th>dew_temperature</th>\n","      <th>precip_depth_1_hr</th>\n","      <th>sea_level_pressure</th>\n","      <th>wind_direction</th>\n","      <th>wind_speed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2017-01-01 00:00:00</td>\n","      <td>17.799999</td>\n","      <td>4.0</td>\n","      <td>11.7</td>\n","      <td>NaN</td>\n","      <td>1021.400024</td>\n","      <td>100.0</td>\n","      <td>3.6</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2017-01-01 01:00:00</td>\n","      <td>17.799999</td>\n","      <td>2.0</td>\n","      <td>12.8</td>\n","      <td>0.0</td>\n","      <td>1022.000000</td>\n","      <td>130.0</td>\n","      <td>3.1</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2017-01-01 02:00:00</td>\n","      <td>16.100000</td>\n","      <td>0.0</td>\n","      <td>12.8</td>\n","      <td>0.0</td>\n","      <td>1021.900024</td>\n","      <td>140.0</td>\n","      <td>3.1</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2017-01-01 03:00:00</td>\n","      <td>17.200001</td>\n","      <td>0.0</td>\n","      <td>13.3</td>\n","      <td>0.0</td>\n","      <td>1022.200012</td>\n","      <td>140.0</td>\n","      <td>3.1</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2017-01-01 04:00:00</td>\n","      <td>16.700001</td>\n","      <td>2.0</td>\n","      <td>13.3</td>\n","      <td>0.0</td>\n","      <td>1022.299988</td>\n","      <td>130.0</td>\n","      <td>2.6</td>\n","    </tr>\n","    <tr>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <td>277238</td>\n","      <td>15</td>\n","      <td>2018-12-31 19:00:00</td>\n","      <td>3.300000</td>\n","      <td>NaN</td>\n","      <td>1.7</td>\n","      <td>NaN</td>\n","      <td>1018.299988</td>\n","      <td>150.0</td>\n","      <td>7.7</td>\n","    </tr>\n","    <tr>\n","      <td>277239</td>\n","      <td>15</td>\n","      <td>2018-12-31 20:00:00</td>\n","      <td>2.800000</td>\n","      <td>NaN</td>\n","      <td>1.1</td>\n","      <td>NaN</td>\n","      <td>1017.799988</td>\n","      <td>140.0</td>\n","      <td>5.1</td>\n","    </tr>\n","    <tr>\n","      <td>277240</td>\n","      <td>15</td>\n","      <td>2018-12-31 21:00:00</td>\n","      <td>2.800000</td>\n","      <td>NaN</td>\n","      <td>1.7</td>\n","      <td>-1.0</td>\n","      <td>1017.200012</td>\n","      <td>140.0</td>\n","      <td>6.2</td>\n","    </tr>\n","    <tr>\n","      <td>277241</td>\n","      <td>15</td>\n","      <td>2018-12-31 22:00:00</td>\n","      <td>2.800000</td>\n","      <td>NaN</td>\n","      <td>2.2</td>\n","      <td>8.0</td>\n","      <td>1016.099976</td>\n","      <td>140.0</td>\n","      <td>5.1</td>\n","    </tr>\n","    <tr>\n","      <td>277242</td>\n","      <td>15</td>\n","      <td>2018-12-31 23:00:00</td>\n","      <td>3.300000</td>\n","      <td>NaN</td>\n","      <td>2.2</td>\n","      <td>20.0</td>\n","      <td>1014.700012</td>\n","      <td>140.0</td>\n","      <td>5.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>277243 rows Ã— 9 columns</p>\n","</div>"],"text/plain":["        site_id           timestamp  air_temperature  cloud_coverage  \\\n","0             0 2017-01-01 00:00:00        17.799999             4.0   \n","1             0 2017-01-01 01:00:00        17.799999             2.0   \n","2             0 2017-01-01 02:00:00        16.100000             0.0   \n","3             0 2017-01-01 03:00:00        17.200001             0.0   \n","4             0 2017-01-01 04:00:00        16.700001             2.0   \n","...         ...                 ...              ...             ...   \n","277238       15 2018-12-31 19:00:00         3.300000             NaN   \n","277239       15 2018-12-31 20:00:00         2.800000             NaN   \n","277240       15 2018-12-31 21:00:00         2.800000             NaN   \n","277241       15 2018-12-31 22:00:00         2.800000             NaN   \n","277242       15 2018-12-31 23:00:00         3.300000             NaN   \n","\n","        dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n","0                  11.7                NaN         1021.400024   \n","1                  12.8                0.0         1022.000000   \n","2                  12.8                0.0         1021.900024   \n","3                  13.3                0.0         1022.200012   \n","4                  13.3                0.0         1022.299988   \n","...                 ...                ...                 ...   \n","277238              1.7                NaN         1018.299988   \n","277239              1.1                NaN         1017.799988   \n","277240              1.7               -1.0         1017.200012   \n","277241              2.2                8.0         1016.099976   \n","277242              2.2               20.0         1014.700012   \n","\n","        wind_direction  wind_speed  \n","0                100.0         3.6  \n","1                130.0         3.1  \n","2                140.0         3.1  \n","3                140.0         3.1  \n","4                130.0         2.6  \n","...                ...         ...  \n","277238           150.0         7.7  \n","277239           140.0         5.1  \n","277240           140.0         6.2  \n","277241           140.0         5.1  \n","277242           140.0         5.1  \n","\n","[277243 rows x 9 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["reduce_mem_usage(train_df)\n","reduce_mem_usage(test_df)\n","reduce_mem_usage(building_meta_df)\n","reduce_mem_usage(weather_train_df)\n","reduce_mem_usage(weather_test_df)"]},{"cell_type":"markdown","metadata":{},"source":["# Save data in feather format"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"ename":"ImportError","evalue":"Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2137\u001b[0;31m         \u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m     def to_parquet(\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(df, path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."]}],"source":["%%time\n","\n","train_df.to_feather('train.feather')\n","test_df.to_feather('test.feather')\n","weather_train_df.to_feather('weather_train.feather')\n","weather_test_df.to_feather('weather_test.feather')\n","building_meta_df.to_feather('building_metadata.feather')\n","sample_submission.to_feather('sample_submission.feather')"]},{"cell_type":"markdown","metadata":{"trusted":true},"source":["# Read data in feather format\n","\n","You can see \"+ Add data\" button on top-right of notebook, press this button and add output of this kernel, then you can use above saved feather data frame for fast loading!\n","\n","Let's see how fast it is."]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"ename":"ImportError","evalue":"Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mstored\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mpyarrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/data_science_lab/.venv/lib/python3.7/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."]}],"source":["%%time\n","\n","train_df = pd.read_feather('train.feather')\n","weather_train_df = pd.read_feather('weather_train.feather')\n","test_df = pd.read_feather('test.feather')\n","weather_test_df = pd.read_feather('weather_test.feather')\n","building_meta_df = pd.read_feather('building_metadata.feather')\n","sample_submission = pd.read_feather('sample_submission.feather')"]},{"cell_type":"markdown","metadata":{"trusted":true},"source":["Reduced 37.1 sec to 1.51 sec!! ðŸ˜„ðŸ˜„ðŸ˜„"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":4}
